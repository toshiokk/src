----.----|----.----|----.----|----.----|----.----|----.----|----.----|----.----|
#TinySegmenterはコンパクトな設計にするために、辞書を使っていません。
TinySegmenterはこんぱくとなせっけいにするために、じしょをつかっていません。
#辞書無しの分かち書きソフトウェアといえば
じしょなしのわかちがきそふとうぇあといえば
#マリモがありますが、マリモとは異なり、
まりもがありますが、まりもとはことなり、
#TinySegmenterは機械学習のみを使って分かち書きを行います。
TinySegmenterはきかいがくしゅうのみをつかってわかちがきをおこないます。
#TinySegmenterは入力文すべての文字について、文字の前が単語境界かどうかを、
TinySegmenterはにゅうりょくぶんすべてのもじについて、
もじのまえがたんごきょうかいかどうかを、
#文字、文字N-gram、ひらがな・カタカナといった文字種情報と
もじ、もじN-gram、ひらがな・かたかなといったもじしゅじょうほうと
#その組み合わせを特徴量として使いながら、学習・分類しています。
そのくみあわせをとくちょうりょうとしてつかいながら、がくしゅう・ぶんるいしています。
#学習データにRWCPコーパスを使っているので、新聞記事には強いですが
がくしゅうでーたにRWCPこーぱすをつかっているので、しんぶんきじにはつよいですが
#チャットやブログといったくだけた文、ひらがなだけの文の解析精度は高くありません。
ちゃっとやぶろぐといったくだけたぶん、ひらがなだけのぶんのかいせきせいどはたかくありません。
#しかし、辞書を使っていないぶん、未知語の解析精度はMeCabより良い場合があります。
しかし、じしょをつかっていないぶん、みちごのかいせきせいどはMeCabよりよいばあいがあります。
#基本的に言語非依存な分かち書きなので、正しく分かち書きされた文が大量にあれば、
きほんてきにげんごひいぞんなわかちがきなので、ただしくわかちがきされたぶんがたいりょうにあれば、
#言語を問わず分かち書きのモデルを構築することができます。
げんごをとわずわかちがきのもでるをこうちくすることができます。
#機械学習を使ううえでも、できあがったモデルのコンパクトさが重要になります。
きかいがくしゅうをつかううえでも、できあがったもでるのこんぱくとさがじゅうようになります。
#SVMやNaive Bayes(ベイジアンフィルター)といった
SVMやNaive Bayes(べいじあんふぃるたー)といった
#機械学習アルゴリズムを使うことは可能ですが、
きかいがくしゅうあるごりずむをつかうことはかのうですが、
#これらが出力するモデルはコンパクトではありません。
これらがしゅつりょくするもでるはこんぱくとではありません。
#一方、冗長な特徴量を極力使わずに
いっぽう、じょうちょうなとくちょうりょうをきょくりょくつかわずに
#モデルをコンパクトに表現できるトリックに
もでるをこんぱくとにひょうげんできるとりっくに
#L1ノルム正則化があります。
L1のるむせいそくかがあります。
#L1ノルム正則化もいろいろなアルゴリズムがありますが(たとえばLog-Linearだとこれ)、
L1のるむせいそくかもいろいろなあるごりずむがありますが(たとえばLog-Linearだとこれ)、
#TinySegmenterは、実装も容易でモデルの圧縮率もいいBoostingを使っています。
TinySegmenterは、じっそうもよういでもでるのあっしゅくりつもいい
Boostingをつかっています。
